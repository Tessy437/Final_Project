{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcc0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tkcalendar in c:\\users\\tessy benson\\anaconda3\\envs\\tensorflow\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: babel in c:\\users\\tessy benson\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tkcalendar) (2.9.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\tessy benson\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from babel->tkcalendar) (2021.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installation of tkinter calendar for search functionality\n",
    "pip install tkcalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136e8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call voice recordimg jupyter notebook for creattion of voice recording based on gTTS module\n",
    "from ipynb.fs.full.Text_Speech_Converter import create_voiceRecording\n",
    "create_voiceRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd41ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "#python version\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8fc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tkcalendar import DateEntry\n",
    "from datetime import date\n",
    "import pyodbc\n",
    "import numpy as np \n",
    "import cv2\n",
    "import time\n",
    "import json  \n",
    "from playsound import playsound\n",
    "from socket import socket\n",
    "import PIL\n",
    "import wave\n",
    "from tkinter import ttk\n",
    "from PIL import Image,ImageTk\n",
    "import cv2\n",
    "from tkinter import *\n",
    "import threading\n",
    "import pyautogui\n",
    "from tkinter import messagebox\n",
    "import datetime\n",
    "import pyaudio\n",
    "import subprocess\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa2a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path definition of emoji pictures of numeric signs\n",
    "digit_emoji_list={0:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\0.png\",\n",
    "                  1:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\1.png\",\n",
    "                  2:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\2.png\",\n",
    "                  3:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\3.png\",\n",
    "                  4:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\4.png\",\n",
    "                  5:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\5.png\",\n",
    "                  6:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\6.png\",\n",
    "                  7:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\7.png\",\n",
    "                  8:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\8.png\",\n",
    "                  9:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_digits\\\\9.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd5a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path definition of emoji pictures of emotions\n",
    "emotion_emoji_list={0:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\angry.png\",\n",
    "                    1:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\disgusted.png\",\n",
    "                    2:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\fearful.png\",\n",
    "                    3:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\happy.png\",\n",
    "                    4:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\neutral.png\",\n",
    "                    5:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\sad.png\",\n",
    "                    6:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoj_emotions\\\\surpriced.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85434cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path definition of emoji pictures of alphabet signs\n",
    "alphabet_emoji_list={0:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\A.png\",\n",
    "                     1:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\B.png\",\n",
    "                     2:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\C.png\",\n",
    "                     3:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\D.png\",\n",
    "                     4:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\E.png\",\n",
    "                     5:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\F.png\",\n",
    "                     6:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\G.png\",\n",
    "                    7:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\H.png\",\n",
    "                     8:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\I.png\",\n",
    "                     9:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\J.png\",\n",
    "                     10:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\K.png\",\n",
    "                     11:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\L.png\",\n",
    "                     12:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\M.png\",\n",
    "                     13:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\N.png\",\n",
    "                    14:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\O.png\",\n",
    "                     15:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\P.png\",\n",
    "                     16:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\Q.png\",\n",
    "                     17:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\R.png\",\n",
    "                     18:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\S.png\",\n",
    "                     19:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\T.png\",\n",
    "                     20:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\U.png\",\n",
    "                     21:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\V.png\",\n",
    "                     22:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\W.png\",\n",
    "                     23:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\X.png\",\n",
    "                     24:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\Y.png\",\n",
    "                     25:\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\emoji_alphabet\\\\Z.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6053e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load digit model input size-(224,224,3)\n",
    "digit_model=load_model(\"C:\\\\Users\\\\Tessy Benson\\\\Documents\\\\Final_Project\\\\Digit\\\\digit_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd5fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining digit labels\n",
    "digit_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3a2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining opencv face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Tessy Benson\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4082c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading emotion model- size -(48,48,1)\n",
    "emotion_model = load_model(\"C:\\\\Users\\\\Tessy Benson\\\\Documents\\\\Final_Project\\\\Emotion\\\\emotion_model_6_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e8db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining emotion labels\n",
    "emotion_label = ['Angry', 'disgust','Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f138418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading alphabet model- size-(224,224,3)\n",
    "alphabet_model=load_model(\"C:\\\\Users\\\\Tessy Benson\\\\Documents\\\\Final_Project\\\\Alphabet\\\\alphabet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb72503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining alphabet labels\n",
    "alphabet_label=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"nothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ec27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display the captured frame from the webcam on the left side label of the interface  - Video mode of the system\n",
    "# first function to be called when launching the interface\n",
    "def show_webcam_only():\n",
    "    if split_flag==False :\n",
    "        ret, frame = capture.read()\n",
    "        cvtColor_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "        img = PIL.Image.fromarray(cvtColor_image)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        label1.imgtk = imgtk\n",
    "        # assigning the captured frame to left side label\n",
    "        label1.configure(image=imgtk)\n",
    "        label1.after(10, show_webcam_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d84cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function called when any of the detection button is clicked\n",
    "def Detection(button_text):\n",
    "    global prediction_probability_status\n",
    "    prediction_probability_status=False\n",
    "    global is_on\n",
    "    global split_flag # This variable becomes true whenever any of the detection button is clicked - Detection mode of the system\n",
    "    global topics_taken   # array variable to assign the topic taken in a session to save to the database \n",
    "    global show_text\n",
    "    global status_variable    # Variable to assign the info message to shown when button is clicked\n",
    "    show_text=[0]\n",
    "    global current_button_text\n",
    "    current_button_text= button_text\n",
    "    if is_on:\n",
    "        f.pack_forget()\n",
    "        split_flag=True\n",
    "        if button_text ==\"Emotion Detection\":\n",
    "            status_variable.set('Emotion detection has started.....')\n",
    "            topic = \"Emotions\"\n",
    "            #changing the configuration of images of detection buttons\n",
    "            emotion_button.config(image = off_image)\n",
    "            digit_button.config(image = on_image)\n",
    "            alphabet_button.config(image = on_image)\n",
    "            if not topic in topics_taken:\n",
    "                topics_taken.append(topic)\n",
    "                \n",
    "        elif button_text ==\"Digit Detection\":\n",
    "            status_variable.set('Digit detection has started.....')\n",
    "            topic = \"Digits\"\n",
    "            digit_button.config(image = off_image)\n",
    "            emotion_button.config(image = on_image)\n",
    "            alphabet_button.config(image = on_image)\n",
    "            if not topic in topics_taken:\n",
    "                topics_taken.append(topic)\n",
    "        else:\n",
    "            topic = \"Alphabets\"\n",
    "            status_variable.set('Alphabet detection has started.....')\n",
    "            alphabet_button.config(image = off_image)\n",
    "            digit_button.config(image = on_image)\n",
    "            emotion_button.config(image = on_image)\n",
    "            if not topic in topics_taken: \n",
    "                topics_taken.append(topic)\n",
    "        # starting detection, showing emoji and playing voice recording threads to make all three functions to be happens simultaneously\n",
    "        detection_thread = threading.Thread(target=show_frame,args=(button_text,))\n",
    "        detection_thread.start()\n",
    "        emoji_thread = threading.Thread(target=show_emoji,args=(button_text,))\n",
    "        emoji_thread.start()  \n",
    "        playsound_thread=threading.Thread(target=play_sound,args=(button_text,))\n",
    "        playsound_thread.start()\n",
    "        is_on = False\n",
    "        status_label.config(textvariable=status_variable)\n",
    "    else: \n",
    "        if button_text ==\"Emotion Detection\":\n",
    "            status_variable.set('Emotion detection stopped')\n",
    "            emotion_button.config(image = on_image)\n",
    "            digit_button.config(image = on_image)\n",
    "            alphabet_button.config(image = on_image)\n",
    "        elif button_text ==\"Digit Detection\":\n",
    "            status_variable.set('Digit detection stopped')\n",
    "            digit_button.config(image = on_image)\n",
    "            emotion_button.config(image = on_image)\n",
    "            alphabet_button.config(image = on_image)\n",
    "        else:\n",
    "            status_variable.set('Alpahbet detection stopped')\n",
    "            alphabet_button.config(image = on_image)\n",
    "            digit_button.config(image = on_image)\n",
    "            emotion_button.config(image = on_image)\n",
    "        split_flag=False\n",
    "        # calling the below function to convert the system from detection to video mode\n",
    "        show_webcam_only()\n",
    "        is_on = True\n",
    "        status_label.config(textvariable=status_variable)\n",
    "        canvas.after(1000,clear_status_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2902f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound(button_text):\n",
    "    if split_flag == True:\n",
    "        # Voice recordings will be played with a delay of every seven seconds on detection\n",
    "        canvas.after(7000, lambda : play_sound_audio(button_text))\n",
    "        canvas.after(7000, lambda : play_sound(button_text))\n",
    "\n",
    "# function to play according to the prediction of the model\n",
    "def play_sound_audio(button_text):\n",
    "     if split_flag == True and current_button_text== button_text:\n",
    "            path=\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\Voice_Recordings\\\\\"\n",
    "            if button_text ==\"Digit Detection\":\n",
    "                if show_text[0] ==0:\n",
    "                    playsound(path + \"0.mp3\")\n",
    "                elif show_text[0] ==1:\n",
    "                    playsound(path + \"1.mp3\") \n",
    "                elif show_text[0] ==2:\n",
    "                    playsound(path + \"2.mp3\") \n",
    "                elif show_text[0] ==3:\n",
    "                    playsound(path + \"3.mp3\") \n",
    "                elif show_text[0] ==4:\n",
    "                    playsound(path + \"4.mp3\") \n",
    "                elif show_text[0] ==5:\n",
    "                    playsound(path + \"5.mp3\") \n",
    "                elif show_text[0] ==6:\n",
    "                    playsound(path + \"6.mp3\") \n",
    "                elif show_text[0] ==7:\n",
    "                    playsound(path + \"7.mp3\") \n",
    "                elif show_text[0] ==8:\n",
    "                    playsound(path + \"8.mp3\") \n",
    "                elif show_text[0] ==9:\n",
    "                    playsound(path + \"9.mp3\") \n",
    "            elif button_text ==\"Emotion Detection\":\n",
    "                if show_text[0] ==0:\n",
    "                    playsound(path + \"angry.mp3\")\n",
    "                elif show_text[0] ==1:\n",
    "                    playsound(path + \"disgust.mp3\") \n",
    "                elif show_text[0] ==2:\n",
    "                    playsound(path + \"fear.mp3\") \n",
    "                elif show_text[0] ==3:\n",
    "                    playsound(path + \"happy.mp3\") \n",
    "                elif show_text[0] ==4:\n",
    "                    playsound(path + \"neutral.mp3\") \n",
    "                elif show_text[0] ==5:\n",
    "                    playsound(path + \"sad.mp3\") \n",
    "                elif show_text[0] ==6:\n",
    "                    playsound(path + \"surprise.mp3\") \n",
    "            elif button_text ==\"Alphabet Detection\":\n",
    "                if show_text[0] ==0:\n",
    "                    playsound(path + \"A.mp3\")\n",
    "                elif show_text[0] ==1:\n",
    "                    playsound(path + \"B.mp3\") \n",
    "                elif show_text[0] ==2:\n",
    "                    playsound(path + \"C.mp3\") \n",
    "                elif show_text[0] ==3:\n",
    "                    playsound(path + \"D.mp3\") \n",
    "                elif show_text[0] ==4:\n",
    "                    playsound(path + \"E.mp3\") \n",
    "                elif show_text[0] ==5:\n",
    "                    playsound(path + \"F.mp3\") \n",
    "                elif show_text[0] ==6:\n",
    "                    playsound(path + \"G.mp3\")\n",
    "                elif show_text[0] ==7:\n",
    "                    playsound(path + \"H.mp3\") \n",
    "                elif show_text[0] ==8:\n",
    "                    playsound(path + \"I.mp3\") \n",
    "                elif show_text[0] ==9:\n",
    "                    playsound(path + \"J.mp3\") \n",
    "                elif show_text[0] ==10:\n",
    "                    playsound(path + \"K.mp3\") \n",
    "                elif show_text[0] ==11:\n",
    "                    playsound(path + \"L.mp3\") \n",
    "                elif show_text[0] ==12:\n",
    "                    playsound(path + \"M.mp3\")\n",
    "                elif show_text[0] ==13:\n",
    "                    playsound(path + \"N.mp3\") \n",
    "                elif show_text[0] ==14:\n",
    "                    playsound(path + \"O.mp3\") \n",
    "                elif show_text[0] ==15:\n",
    "                    playsound(path + \"P.mp3\") \n",
    "                elif show_text[0] ==16:\n",
    "                    playsound(path + \"Q.mp3\") \n",
    "                elif show_text[0] ==17:\n",
    "                    playsound(path + \"R.mp3\") \n",
    "                elif show_text[0] ==18:\n",
    "                    playsound(path + \"S.mp3\")\n",
    "                elif show_text[0] ==19:\n",
    "                    playsound(path + \"T.mp3\") \n",
    "                elif show_text[0] ==20:\n",
    "                    playsound(path + \"U.mp3\") \n",
    "                elif show_text[0] ==21:\n",
    "                    playsound(path + \"V.mp3\") \n",
    "                elif show_text[0] ==22:\n",
    "                    playsound(path + \"W.mp3\") \n",
    "                elif show_text[0] ==23:\n",
    "                    playsound(path + \"X.mp3\") \n",
    "                elif show_text[0] ==24:\n",
    "                    playsound(path + \"Y.mp3\")\n",
    "                elif show_text[0] ==25:\n",
    "                    playsound(path + \"Z.mp3\")\n",
    "     elif split_flag == False:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd02a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that display emoji pictures of the detected label on the right side of the interface \n",
    "def show_emoji(button_text):\n",
    "    if split_flag == True:\n",
    "        if show_text[0] == 26:\n",
    "            # condition to check if the detected label is NOTHING class of alphabet dataset. If so, no emoji pictures will be shown\n",
    "            label2.configure(image = \"\")\n",
    "            label2.after(10,lambda : show_emoji(button_text))\n",
    "        else:\n",
    "            if prediction_probability_status==True:\n",
    "                if button_text ==\"Digit Detection\":\n",
    "                    frame2 = cv2.imread(digit_emoji_list[show_text[0]])\n",
    "                elif button_text ==\"Alphabet Detection\":\n",
    "                    frame2 = cv2.imread(alphabet_emoji_list[show_text[0]]) \n",
    "                else:\n",
    "                    frame2 = cv2.imread(emotion_emoji_list[show_text[0]]) \n",
    "                img2 = PIL.Image.fromarray(frame2)\n",
    "                imgtk2 = ImageTk.PhotoImage(image=img2)\n",
    "                label2.imgtk2 = imgtk2\n",
    "                label2.configure(image = imgtk2)\n",
    "            label2.after(10,lambda : show_emoji(button_text))\n",
    "    else:\n",
    "        label2.configure(image = \"\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be263f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to resize the backgroung image of the main interface whenever size of interface window changes\n",
    "def background_image_resize(e):\n",
    "    global original_image, resized_image, image\n",
    "    original_image = PIL.Image.open(\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\backgd.png\")\n",
    "    resized_image = original_image.resize((e.width, e.height), PIL.Image.ANTIALIAS)\n",
    "    image = ImageTk.PhotoImage(resized_image)\n",
    "    canvas.create_image(0, 0, image=image, anchor='nw')\n",
    "\n",
    "# function to display the counter(timer) label on the interface\n",
    "def counter_start():\n",
    "    global start_timer\n",
    "    start_timer = True\n",
    "    global hrs, mints, sec\n",
    "    sec += 1\n",
    "    if sec == 60:\n",
    "        mints += 1\n",
    "        sec = 0\n",
    "    if mints == 60:\n",
    "        hrs += 1\n",
    "        mints = 0\n",
    "    if hrs>9:\n",
    "        display_hrs=f'{hrs}'\n",
    "    else:\n",
    "        display_hrs=f'0{hrs}'\n",
    "    if mints>9:\n",
    "        display_min=f'{mints}'\n",
    "    else:\n",
    "        display_min=f'0{mints}'\n",
    "    if sec>9:\n",
    "        display_sec=f'{sec}'\n",
    "    else:\n",
    "        display_sec=f'0{sec}'\n",
    "\n",
    "    to_display=display_hrs + ':' + display_min + ':' + display_sec\n",
    "    counter_label.config(text=to_display)\n",
    "    counter_label.after(1000, counter_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bda97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that handles database saving on main interface closing \n",
    "def closing_fnt():\n",
    "    global Emotion_Detection, Digit_Detection,Alphabet_Detection\n",
    "    global final_mark\n",
    "    global quiz_quit\n",
    "    Emotion_Detection=0\n",
    "    Digit_Detection=0\n",
    "    Alphabet_Detection=0\n",
    "    counter_time=counter_label.cget(\"text\")\n",
    "    # checkinh which all topics taken on the session\n",
    "    if \"Emotions\" in topics_taken:\n",
    "        Emotion_Detection=1\n",
    "    if \"Digits\" in topics_taken:\n",
    "        Digit_Detection=1\n",
    "    if \"Alphabets\" in topics_taken:\n",
    "        Alphabet_Detection=1\n",
    "    now = datetime.datetime.now()\n",
    "    date_to_db=now.date()\n",
    "    if quiz_done == False:\n",
    "        final_mark=\"No test conducted\"\n",
    "    elif quiz_quit == True:\n",
    "         # checking if the student quitted from the quiz\n",
    "        final_mark=\"Quitted from Test\"\n",
    "    # making connection with the SQL server database to insert the session details to the \"History\" table\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    cursor = connection.cursor()\n",
    "    insert_statement=\"Insert into History (Session_date,Session_start_time,Duration,Emotion_detection,Digit_detection,Alphabet_detecetion,Total_marks) values (?, ?,?,?,?,?,?)\"\n",
    "    cursor.execute(insert_statement,str(date_to_db),str(Session_start_time).split(\".\")[0],str(counter_time),Emotion_Detection,Digit_Detection,Alphabet_Detection,final_mark)\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    root_instance.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb314541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search functionality \n",
    "def search_functionality(selected_date):\n",
    "    # disabiling the search button after it is clicked\n",
    "    btn.config(state=DISABLED)\n",
    "    # configuring new interface on top of main interface\n",
    "    search_root = Toplevel()\n",
    "    sel_date=selected_date.strftime('%d-%m-%Y')\n",
    "    title=\"Search Results for the date \" + str(sel_date)\n",
    "    search_root.title(title)\n",
    "    search_root.geometry(\"1100x500\")\n",
    "    search_canvas= Canvas(search_root, width= 1100, height=500)\n",
    "    search_canvas.pack(fill= BOTH, expand= True)\n",
    "    # To show background image for search interface\n",
    "    search_background_img = PhotoImage(file=\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\search_5.png\")\n",
    "    search_canvas.create_image(0,0,image=search_background_img,anchor='center') \n",
    "    global Topics\n",
    "    Topics=[]\n",
    "    search_style = ttk.Style()\n",
    "    search_style.theme_use('default')\n",
    "    search_style.configure(\"Treeview\",rowheight=25)\n",
    "    search_style.configure('Treeview.Heading', font=('Arial Bold', 10))\n",
    "    search_style.map('Treeview',background=[('selected', \"DODGERBLUE4\")])\n",
    "    search_frame = Frame(search_canvas)\n",
    "    search_frame.pack(pady=120)\n",
    "    #adding scrollbar to the search table\n",
    "    scrollbar = Scrollbar(search_frame,orient =\"vertical\",)\n",
    "    scrollbar.pack(side=RIGHT, fill=Y)\n",
    "    search_tree = ttk.Treeview(search_frame, yscrollcommand=scrollbar.set)\n",
    "    search_tree.pack()\n",
    "    scrollbar.config(command=search_tree.yview)\n",
    "    search_tree['columns'] = (\"Session_Date\", \"Time\", \"Duration\", \"Topics\",\"final_marks\")\n",
    "    #data to bind\n",
    "    search_tree.column(\"#0\", width=0, stretch=NO)\n",
    "    search_tree.column(\"Session_Date\", anchor=W, width=140)\n",
    "    search_tree.column(\"Time\", anchor=CENTER, width=100)\n",
    "    search_tree.column(\"Duration\", anchor=CENTER, width=140)\n",
    "    search_tree.column(\"Topics\", anchor=CENTER, width=230)\n",
    "    search_tree.column(\"final_marks\", anchor=CENTER, width=200)\n",
    "    #headings to show\n",
    "    search_tree.heading(\"#0\", text=\"\", anchor=W)\n",
    "    search_tree.heading(\"Session_Date\", text=\"Session_Date\", anchor=W)\n",
    "    search_tree.heading(\"Time\", text=\"Time\", anchor=CENTER)\n",
    "    search_tree.heading(\"Duration\", text=\"Duration\", anchor=CENTER)\n",
    "    search_tree.heading(\"Topics\", text=\"Topics_taken\", anchor=CENTER)\n",
    "    search_tree.heading(\"final_marks\", text=\"Total Marks Obtained\", anchor=CENTER)\n",
    "    \n",
    "    # function to resize search interface background image\n",
    "    def search_background_image_resize(e):\n",
    "        global search_original_image, search_resized_image, search_image\n",
    "        search_original_image = PIL.Image.open(\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\search_5.png\")\n",
    "        search_resized_image = search_original_image.resize((e.width, e.height), PIL.Image.ANTIALIAS)\n",
    "        search_image = ImageTk.PhotoImage(search_resized_image)\n",
    "        search_canvas.create_image(0, 0, image=search_image, anchor='nw')\n",
    "    \n",
    "    #function to reset the selected date in the search calender to today date on closing the search interface\n",
    "    def Reset_to_TodayDate():\n",
    "        global date_entry\n",
    "        now = datetime.datetime.now()\n",
    "        todays_date=now.date()\n",
    "        date_entry.set_date(todays_date)\n",
    "        btn.config(state=ACTIVE)\n",
    "        search_root.destroy()\n",
    "        \n",
    "    #function to retrieve session history from SQL database and display it in a tree view\n",
    "    def Treeview_data(selected_date):\n",
    "        global Topics\n",
    "        connection = pyodbc.connect(connection_string)\n",
    "        cursor = connection.cursor()\n",
    "        statement=\"SELECT * FROM History WHERE Session_date LIKE ?\"\n",
    "        parameter=f'%{selected_date}%'\n",
    "        cursor.execute(statement, parameter)\n",
    "        data = cursor.fetchall()\n",
    "        if len(data) >0 :\n",
    "            global val\n",
    "            val = 0\n",
    "            for col in data:\n",
    "                Topics=[]\n",
    "                # Formatting date and time from database before showing it in the tree view\n",
    "                Session_Date=datetime.datetime.strptime(col[0],\"%Y-%m-%d\").strftime('%d-%m-%Y')\n",
    "                Time_from_db=datetime.datetime.strptime(datetime.datetime.strptime(col[1].split('.')[0],\"%H:%M:%S\").strftime('%H:%M'), \"%H:%M\")\n",
    "                Time=Time_from_db.strftime(\"%I:%M %p\")\n",
    "                Duration=col[2].split('.')[0]\n",
    "                final_marks=col[6]\n",
    "                if col[3] == 1:\n",
    "                    Topics.append(\"Emotions\")\n",
    "                if col[4] == 1:\n",
    "                    Topics.append(\"Digits\")\n",
    "                if col[5] == 1:\n",
    "                    Topics.append(\"Alphabets\")\n",
    "                if len(Topics) >= 2:\n",
    "                    Topics = \",\".join(Topics)\n",
    "                # inserting retrieved data to tree view\n",
    "                if val % 2 == 0:\n",
    "                    search_tree.insert('','end', text='', values=(Session_Date,Time,Duration,Topics,final_marks), tags=('row_divisible',))\n",
    "                else:\n",
    "                    search_tree.insert('','end',text='', values=(Session_Date,Time,Duration,Topics,final_marks), tags=('row_indivisible',))\n",
    "                val += 1\n",
    "        else:\n",
    "            # condition to display proper message if no session taken on the selected search date\n",
    "            search_frame.pack(pady=200)\n",
    "            message=\"No session were taken on \"+str(sel_date)\n",
    "            msg = Message(search_frame, text =message,bg='lavenderBlush2', font=('times', 24, 'italic'),width=800,justify=CENTER)\n",
    "            msg.pack()\n",
    "            search_tree.destroy()\n",
    "            scrollbar.destroy()\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "    \n",
    "    search_tree.tag_configure('row_indivisible', background=\"white\")\n",
    "    search_tree.tag_configure('row_divisible', background=\"sky blue\")\n",
    "\n",
    "    Treeview_data(selected_date)\n",
    "    # defining binding events of search interface\n",
    "    search_canvas.bind(\"<Configure>\", search_background_image_resize)\n",
    "    search_root.protocol(\"WM_DELETE_WINDOW\", Reset_to_TodayDate)\n",
    "    search_root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5f9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz functionality\n",
    "def open_quiz_window():\n",
    "    quiz_button.config(state=DISABLED)\n",
    "    # configuring quiz interface\n",
    "    quiz_window=Toplevel()\n",
    "    quiz_window.geometry(\"1000x600\")  \n",
    "    quiz_window.title(\"Quiz\")\n",
    "    quiz_canvas= Canvas(quiz_window, width= 1200, height=200)\n",
    "    quiz_canvas.pack(fill= BOTH, expand= True)\n",
    "    # To show background image\n",
    "    quiz_background_img = PhotoImage(file=\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\quiz_2.png\")\n",
    "    quiz_canvas.create_image(0,0,image=quiz_background_img,anchor='nw') \n",
    "    global quiz_done\n",
    "    quiz_done=True\n",
    "    global question_Number\n",
    "    question_Number=0\n",
    "    global correct_answers\n",
    "    correct_answers = 0 \n",
    "    global Selected_option\n",
    "    Selected_option = IntVar()\n",
    "    # loading quiz data from external json file\n",
    "    with open('C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\data.json') as file:  \n",
    "        quiz_list = json.load(file)    \n",
    "        questions = (quiz_list['ques'])  \n",
    "        choices = (quiz_list['choices'])  \n",
    "        right_answers = (quiz_list[ 'ans']) \n",
    "        qn_images=(quiz_list[\"images\"])\n",
    "    global qn_Size\n",
    "    qn_Size = len(questions) \n",
    "    \n",
    "    # function to resize quiz interface background image\n",
    "    def quiz_background_image_resize(e):\n",
    "        global quiz_original_image, quiz_resized_image, quiz_image\n",
    "        quiz_original_image = PIL.Image.open(\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\quiz_2.png\")\n",
    "        quiz_resized_image = quiz_original_image.resize((e.width, e.height), PIL.Image.ANTIALIAS)\n",
    "        quiz_image = ImageTk.PhotoImage(quiz_resized_image)\n",
    "        quiz_canvas.create_image(0, 0, image=quiz_image, anchor='nw')\n",
    "        \n",
    "    # function to display questions and its corresponding images    \n",
    "    def Frame_Question(quesNumber):\n",
    "        original_img = PIL.Image.open(qn_images[quesNumber])\n",
    "        resized_img = original_img.resize((200,200))\n",
    "        global qn_img\n",
    "        qn_img = ImageTk.PhotoImage(resized_img)\n",
    "        ques_img_label = Label(quiz_canvas,anchor = 'center',image=qn_img)  \n",
    "        ques_img_label.place(x = 300, y = 100)\n",
    "        ques_text_label = Label(quiz_canvas,text = questions[quesNumber],bg=\"#f7be00\",width = 35,font = ('ariel', 16, 'bold'),anchor = 'w')    \n",
    "        ques_text_label.place(x = 100, y = 320)\n",
    " \n",
    "    # function to display 4 radiobuttons for the options of the questions\n",
    "    def add_radioButtons():  \n",
    "        radioButtons_List = []    \n",
    "        position = 370  \n",
    "        while len(radioButtons_List) < 4:  \n",
    "            radio_button = Radiobutton(quiz_canvas,font = ('ariel', 12, 'bold'),variable = Selected_option,value = len(radioButtons_List) + 1,bg =\"#f7be00\")\n",
    "            radioButtons_List.append(radio_button)   \n",
    "            radio_button.place(x = 130, y = position)  \n",
    "            position += 40   \n",
    "        return radioButtons_List\n",
    "    \n",
    "    #function to display the four alternative options for each question\n",
    "    def show_Options():  \n",
    "        index = 0  \n",
    "        global Selected_option\n",
    "        global question_Number\n",
    "        global options\n",
    "        Selected_option.set(0)  \n",
    "        for choice in choices[question_Number]:  \n",
    "            options[index]['text'] = choice  \n",
    "            index += 1  \n",
    "        \n",
    "    # function called on clicking the Next button in quiz interface\n",
    "    def button_next(): \n",
    "        global correct_answers\n",
    "        global question_Number\n",
    "        #condition to check if the option selected in previous question is correct or not\n",
    "        if check_option(question_Number):  \n",
    "            correct_answers += 1  \n",
    "        question_Number += 1\n",
    "        # condition to check if the current question is the last one in the quiz\n",
    "        if question_Number == qn_Size:\n",
    "            #if yes, show the result in the interface\n",
    "            Result() \n",
    "            quiz_window.destroy()\n",
    "        else:  \n",
    "            # if no, show the next question and its options\n",
    "            Frame_Question(question_Number) \n",
    "            show_Options() \n",
    "            \n",
    "    # function t calculate the final result and shows the corresponding picture message\n",
    "    def Result():\n",
    "        quiz_button.config(state=ACTIVE)\n",
    "        global correct_answers\n",
    "        global final_mark\n",
    "        wrong_answers = qn_Size - correct_answers  \n",
    "        right_answer_count = f\"[ Correct Answers: {correct_answers} , \"  \n",
    "        wrong_answer_count = f\"Wrong Answers: {wrong_answers} ]\"  \n",
    "        # calculating the percentage \n",
    "        final_mark = int(correct_answers / qn_Size * 100) \n",
    "        Result = f\"Score: {final_mark}%\"  \n",
    "        #Three condition to display messages\n",
    "        if final_mark > 80:\n",
    "            img = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\well_done.png\")\n",
    "\n",
    "        elif 51 <= final_mark <= 79:\n",
    "            img = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\keep.png\")\n",
    "        else:\n",
    "            img = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\keep_try.png\")\n",
    "        # assigning the messages to the label\n",
    "        label2.image = img\n",
    "        label2.configure(image = img)\n",
    "        label2.configure(compound='bottom')\n",
    "        label2.configure(text= f\"{Result} {right_answer_count} {wrong_answer_count}\")\n",
    "        label2.configure(font='Helvetica 12 italic')\n",
    "        label2.after(3000,clear_image) #clear image and text afte 3 second\n",
    "             \n",
    "    # checking if the option selected is correct or not        \n",
    "    def check_option(quesNumber): \n",
    "        if Selected_option.get() == right_answers[quesNumber]:  \n",
    "            return True\n",
    "        \n",
    "    def clear_image():\n",
    "        label2.configure(image = \"\")\n",
    "        label2.configure(text= \"\")\n",
    "        \n",
    "    # function to call when the quiz is quitted\n",
    "    def quiz_quit():\n",
    "        quiz_button.config(state=ACTIVE)\n",
    "        global quiz_quit\n",
    "        quiz_quit=True\n",
    "        quiz_window.destroy()\n",
    "    # function to call when the quiz interface is closed  \n",
    "    def close():\n",
    "        quiz_button.config(state=ACTIVE)\n",
    "        quiz_window.destroy()\n",
    "        \n",
    "    # next and quit button configuration in the interface\n",
    "    next_button = Button(quiz_canvas,text = \"Next\",width = 10,bg = \"green\", fg = \"white\",font = (\"ariel\", 16, \"bold\"),activebackground=\"green\",command=button_next)   \n",
    "    next_button.place(x = 700, y = 500)  \n",
    "    quit_button = Button( quiz_canvas,text = \"Quit\",width = 4,bg = \"red\",activebackground=\"red\",fg = \"white\", font = (\"ariel\", 16, \" bold\"),command=quiz_quit)   \n",
    "    quit_button.place(x = 905, y = 5) \n",
    "    \n",
    "    \n",
    "    Frame_Question(question_Number) \n",
    "    global options\n",
    "    options=add_radioButtons() \n",
    "    show_Options()\n",
    "    #binding events of the quiz interface\n",
    "    quiz_canvas.bind(\"<Configure>\", quiz_background_image_resize)\n",
    "    quiz_window.protocol(\"WM_DELETE_WINDOW\", close)\n",
    "    quiz_window.mainloop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3728545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear():\n",
    "    label2.configure(image = \"\")\n",
    "    label2.configure(text= \"\")\n",
    "    quick_quiz_button.config(state=ACTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73dfca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick quiz functionality\n",
    "#show 3 checkbox options for the quick quiz question\n",
    "def add_checkButtons(): \n",
    "    check_Buttons_List = []  \n",
    "    option_list=[\"Angry\",\"Happy\",\"disgust\"]\n",
    "    while len(check_Buttons_List) < 3:\n",
    "        check_button = Checkbutton(quiz_frame,font = ('ariel', 12, 'bold'),text=option_list[len(check_Buttons_List)],width=10,\n",
    "                command=checkbtn_selected,\n",
    "                variable=check_box_variable,\n",
    "                onvalue=len(check_Buttons_List)+1)\n",
    "        check_Buttons_List.append(check_button)    \n",
    "        check_button.pack()\n",
    "# function to be called when the \"quick_quiz\" button is clicked       \n",
    "def quick_quiz():\n",
    "    quick_quiz_button.config(state=DISABLED)\n",
    "    if try_again_quiz == True:\n",
    "        for widget in quiz_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        quiz_frame.place_forget()   \n",
    "    global check_box_variable\n",
    "    check_box_variable =IntVar()\n",
    "    # display the quiz question\n",
    "    quiz_image = PIL.Image.open(\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\happy.png\")\n",
    "    quiz_resized_image = quiz_image.resize((400, 400), PIL.Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(quiz_resized_image)\n",
    "    label2.img = img\n",
    "    label2.configure(image = img,text=\"Choose the shown emotion\",compound=TOP,font= ('Helvetica 15 bold'))\n",
    "    add_checkButtons()\n",
    "    quiz_frame.grid(row=0,column=0)\n",
    "    quiz_frame.place(x=1200,y=700)\n",
    "    \n",
    "# function called when any option is selected for the quick quiz    \n",
    "def checkbtn_selected():\n",
    "    canvas.after(500, checkbtn_value_selected)\n",
    "# function to be called when quit button is clicked\n",
    "def quick_quiz_stop():\n",
    "    clear()\n",
    "    for widget in quiz_frame.winfo_children():\n",
    "        widget.destroy()\n",
    "        quiz_frame.place_forget()\n",
    "    \n",
    "# function that checks if the selected option is correct and dispay corresponding mesaages according to the selection\n",
    "def checkbtn_value_selected():\n",
    "    global try_again_quiz\n",
    "    if check_box_variable.get() == 2 :\n",
    "        img = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\correct_answer.png\")\n",
    "        label2.img = img\n",
    "        label2.configure(image = img,text=\"Correct Answer\")\n",
    "        for widget in quiz_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        quiz_frame.place_forget()\n",
    "        label2.after(2000,clear)\n",
    "    else:\n",
    "        try_again_quiz=True\n",
    "        try_again_image = PIL.Image.open(\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\try.png\")\n",
    "        try_again_resized_image = try_again_image.resize((400, 400), PIL.Image.ANTIALIAS)\n",
    "        try_again_img = ImageTk.PhotoImage(try_again_resized_image)\n",
    "        label2.img = try_again_img\n",
    "        label2.configure(image = try_again_img,text=\"\")\n",
    "        for widget in quiz_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        quiz_frame.place(x=1260,y=700)\n",
    "        quit_button=Button(quiz_frame,state=ACTIVE,font= ('Helvetica 15 bold'),image=quit_image,text='Quit',compound= RIGHT,\n",
    "                     command=quick_quiz_stop)\n",
    "        quit_button.pack(side=RIGHT,ipadx=10)\n",
    "        try_again_button=Button(quiz_frame,state=ACTIVE,font= ('Helvetica 15 bold'),image=try_image,text='Try Again',compound= RIGHT,\n",
    "                     command=quick_quiz)\n",
    "        try_again_button.pack(side=RIGHT,ipadx=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf161d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion that makes model prediction on clicking the detection button\n",
    "def show_frame(button_text):\n",
    "    print(button_text)\n",
    "    if split_flag == True:\n",
    "        global prediction_probability_status\n",
    "        global model;\n",
    "        global label\n",
    "        model=digit_model\n",
    "        label=digit_label\n",
    "        global pred\n",
    "        pred=0\n",
    "        prediction_probability = 0\n",
    "        ret, frame = capture.read()\n",
    "        if button_text ==\"Emotion Detection\":\n",
    "            prediction_probability_status=False\n",
    "            model=emotion_model\n",
    "            label=emotion_label\n",
    "            gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            #detecting face using opencv cascade classifier\n",
    "            detected_faces = face_cascade.detectMultiScale(gray_image, 1.1, 6, minSize=(150, 150))\n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                #drawing bounding box around face to capture the emotion expressed\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), thickness=2)\n",
    "                roi_gray = gray_image[y:y + w, x:x + h]\n",
    "                #resizing the captured image frame as per the model expect\n",
    "                roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "                if np.sum([roi_gray])!=0:\n",
    "                    img = roi_gray.astype('float32')/255\n",
    "                    img=img_to_array(img)\n",
    "                    img = np.expand_dims(img, axis=0)\n",
    "                    pred = np.argmax(model.predict(img))\n",
    "                    color = (0,0,255)\n",
    "                    #model prediction\n",
    "                    prediction  = np.array(model.predict(img))\n",
    "                    prediction_probability = prediction[0, prediction.argmax()]\n",
    "                    # show label text only if predcition praobability greater than 50%\n",
    "                    if prediction_probability >0.5:\n",
    "                        prediction_probability_status=True\n",
    "                        maxindex = int(pred)\n",
    "                        show_text[0]=maxindex\n",
    "                        color = (0,0,255)\n",
    "                        #showing the predcited label on top of the bounding box\n",
    "                        cv2.putText(frame,label[pred], (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                        cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "                        img = PIL.Image.fromarray(cv2image)\n",
    "                        imgtk = ImageTk.PhotoImage(image=img)\n",
    "                        label1.imgtk = imgtk\n",
    "                        label1.configure(image=imgtk)\n",
    "            label1.after(10, lambda : show_frame(button_text))\n",
    "        elif button_text ==\"Digit Detection\" :\n",
    "            prediction_probability_status=False\n",
    "            model=digit_model\n",
    "            label=digit_label \n",
    "            # drawing bounding box\n",
    "            cv2.rectangle(frame, (100, 100), (500, 500), (255, 255, 255), 2)\n",
    "            roi = frame[100:500, 100:500]\n",
    "            img = cv2.resize(roi, (224, 224))\n",
    "            img = img_to_array(img)    \n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img = img.astype('float32')/255\n",
    "            pred = np.argmax(model.predict(img))\n",
    "            prediction  = np.array(model.predict(img))\n",
    "            prediction_probability = prediction[0, prediction.argmax()]\n",
    "            if prediction_probability >0.5:\n",
    "                prediction_probability_status=True\n",
    "                maxindex = int(pred)\n",
    "                show_text[0]=maxindex\n",
    "                color = (0,0,255)\n",
    "                cv2.putText(frame, label[pred], (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "                img = PIL.Image.fromarray(cv2image)\n",
    "                imgtk = ImageTk.PhotoImage(image=img)\n",
    "                label1.imgtk = imgtk\n",
    "                label1.configure(image=imgtk)\n",
    "            label1.after(10, lambda : show_frame(button_text))\n",
    "        elif button_text ==\"Alphabet Detection\" :\n",
    "            prediction_probability_status=False\n",
    "            model=alphabet_model\n",
    "            label=alphabet_label\n",
    "            cv2.rectangle(frame, (100, 100), (500, 500), (255, 255, 255), 2)\n",
    "            roi = frame[100:500, 100:500]\n",
    "            img = cv2.resize(roi, (224, 224))\n",
    "            img = img_to_array(img)    \n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img = img.astype('float32')/255\n",
    "            pred = np.argmax(model.predict(img))\n",
    "            prediction  = np.array(model.predict(img))\n",
    "            prediction_probability = prediction[0, prediction.argmax()]\n",
    "            if prediction_probability >0.5:\n",
    "                prediction_probability_status=True\n",
    "                maxindex = int(pred)\n",
    "                show_text[0]=maxindex\n",
    "                color = (0,0,255)\n",
    "                if show_text[0] != 26:\n",
    "                    cv2.putText(frame,label[pred], (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "                img = PIL.Image.fromarray(cv2image)\n",
    "                imgtk = ImageTk.PhotoImage(image=img)\n",
    "                label1.imgtk = imgtk\n",
    "                label1.configure(image=imgtk)\n",
    "            label1.after(10, lambda : show_frame(button_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fec87f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion that clears the info message shown at the bottom of the interface\n",
    "def clear_status_text():\n",
    "    global status_variable\n",
    "    status_variable=StringVar() \n",
    "    status_label.config(textvariable=status_variable)\n",
    "    screenshot_button.config(state=ACTIVE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "746403ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function called when recording button is clicked\n",
    "import time\n",
    "def Recording():\n",
    "    global status_variable\n",
    "    global recording_is_on\n",
    "    global stop_recording\n",
    "    global frame_counts\n",
    "    frame_counts=1\n",
    "    if recording_is_on:\n",
    "        status_variable.set(\"Recording has started.....\")\n",
    "        status_label.config(textvariable=status_variable)\n",
    "        stop_recording=False\n",
    "        recording_button.config(image = off_image)\n",
    "        #starting both video and audio thread\n",
    "        video_thread = threading.Thread(target=record_video)\n",
    "        video_thread.start()\n",
    "        audio_thread = threading.Thread(target=record_audio)\n",
    "        audio_thread.start()\n",
    "        recording_is_on=False\n",
    "    else:\n",
    "        stop_recording=True\n",
    "        recording_button.config(image = on_image)\n",
    "        # creating folder structure to save the recorded file\n",
    "        current_folder= os.getcwd()\n",
    "        now = datetime.datetime.now()\n",
    "        current_date = now.date()\n",
    "        date_format=current_date.strftime('%d-%m-%Y')\n",
    "        recording_directory = os.path.join(current_folder, r'Recordings')\n",
    "        if not os.path.exists(recording_directory):\n",
    "            os.makedirs(recording_directory)\n",
    "        current_date_directory=os.path.join(recording_directory,date_format)\n",
    "        if not os.path.exists(current_date_directory):\n",
    "            os.makedirs(current_date_directory)\n",
    "        # counting the number of files in the folder to give appropriate name to the recorded file\n",
    "        file_counts=len([name for name in os.listdir(current_date_directory)])\n",
    "        recording_file=\"Recording\"+ str((file_counts+1))\n",
    "        # merging audio and video files using the command line tool\n",
    "        cmd='ffmpeg -y -i '+ audio_file_name+ ' -r 30 -i '+ video_file_name+ ' -filter:a aresample=async=1 -c:a flac -c:v copy '+ recording_file + '.mkv'\n",
    "        subprocess.call(cmd, shell=True)\n",
    "        source_location=current_folder  +'\\\\'+ recording_file +\".mkv\"\n",
    "        # moving the recorded file to the specified location\n",
    "        shutil.move(source_location,current_date_directory)\n",
    "        #deleting the separate audio and video file after mering \n",
    "        os.remove(current_folder  +'\\\\'+ audio_file_name)\n",
    "        os.remove(current_folder  +'\\\\'+video_file_name)\n",
    "        recording_is_on=True\n",
    "        status_variable.set(\"Recording stopped.Recorded file saved successfully to the local folder\")\n",
    "        status_label.config(textvariable=status_variable)\n",
    "        canvas.after(2000,clear_status_text)\n",
    "        \n",
    "# function that record video file        \n",
    "def record_video():\n",
    "    global video_file_name\n",
    "    global frame_counts\n",
    "    timer_start = time.time()\n",
    "    #assigning name and format to captured video\n",
    "    name = 'screen_recording_'\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%H%M%S\")\n",
    "    file_format = 'mp4'\n",
    "    video_file_name = name + str(date) + '.' + file_format\n",
    "    SCREEN_SIZE = tuple(pyautogui.size())\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    #frame per second\n",
    "    fps = 12\n",
    "    out = cv2.VideoWriter(video_file_name, fourcc, fps, (SCREEN_SIZE))\n",
    "    # writing the video frames to the specified file\n",
    "    while True:\n",
    "        img=pyautogui.screenshot()\n",
    "        frame = np.array(img)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        out.write(frame)\n",
    "        frame_counts += 1\n",
    "        if stop_recording ==True:\n",
    "            break\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#function that record audio files\n",
    "def record_audio():\n",
    "    global audio_file_name\n",
    "    frames = []\n",
    "    # create stream object\n",
    "    stream = pyaudio.PyAudio().open(format=pyaudio.paInt16,channels=2,rate=44100,frames_per_buffer=1024,input=True)\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%H%M%S\")\n",
    "    file_format = 'wav'\n",
    "    name = 'audio_recording_'\n",
    "    audio_file_name = name + str(date) + '.' + file_format\n",
    "    # reading the voice and writing it to the corresponding file\n",
    "    while True:\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data) \n",
    "        if stop_recording ==True:\n",
    "            wf = wave.open(audio_file_name, 'wb')\n",
    "            wf.setnchannels(2)\n",
    "            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "            wf.setframerate(44100)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "            wf.close()\n",
    "            now = datetime.datetime.now()\n",
    "            current_date = now.time()\n",
    "            break\n",
    "\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4ba5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen shot function\n",
    "def screen_capture():\n",
    "    screenshot_button.config(state=DISABLED)\n",
    "    global status_variable\n",
    "    status_variable.set(\"Screen shot captured\")\n",
    "    status_label.config(textvariable=status_variable)\n",
    "    # define the region to capture the screen shot\n",
    "    screenshot = pyautogui.screenshot(region=(0,0, 1920, 900))\n",
    "    #create folder structure for saving the captured screen shot\n",
    "    current_folder= os.getcwd()\n",
    "    now = datetime.datetime.now()\n",
    "    current_date = now.date()\n",
    "    date_format=current_date.strftime('%d-%m-%Y')\n",
    "    capture_directory = os.path.join(current_folder, r'Screen_Capture')\n",
    "    if not os.path.exists(capture_directory):\n",
    "        os.makedirs(capture_directory)\n",
    "    current_date_capture_directory=os.path.join(capture_directory,date_format)\n",
    "    if not os.path.exists(current_date_capture_directory):\n",
    "        os.makedirs(current_date_capture_directory)\n",
    "    file_counts=len([name for name in os.listdir(current_date_capture_directory)])\n",
    "    capture_file=\"Screen_Capture\"+ str((file_counts+1))+'.png'\n",
    "    path = os.path.join(current_date_capture_directory, capture_file)\n",
    "    # saving the screenshot\n",
    "    screenshot.save(path)\n",
    "    canvas.after(1000,clear_status_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cd6670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libaries\n",
    "from win32api import GetSystemMetrics\n",
    "from PIL import ImageGrab\n",
    "from PIL import ImageTk, Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from tkinter import messagebox as mb  \n",
    "from playsound import playsound\n",
    "from socket import socket\n",
    "import PIL\n",
    "import wave\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import shutil\n",
    "from tkinter import *\n",
    "import threading\n",
    "import pyautogui\n",
    "from tkinter import messagebox\n",
    "import datetime\n",
    "import pyaudio\n",
    "import subprocess\n",
    "from functools import partial\n",
    "hrs, mints, sec = 0, 0, 0\n",
    "global topics_taken\n",
    "topics_taken=[]\n",
    "global final_mark\n",
    "final_mark=0\n",
    "global Session_start_time \n",
    "now=datetime.datetime.now()\n",
    "Session_start_time=now.time()\n",
    "global connection_string\n",
    "# defining connection string of the SQL server\n",
    "connection_string = (\"Driver={SQL Server};\"\n",
    "            \"Server=LAPTOP-5Q3E4JBP\\SQLEXPRESS;\"\n",
    "            \"Database=Main_Project;\"\n",
    "            \"Trusted_Connection=yes;\")\n",
    "global quiz_done\n",
    "quiz_done=False\n",
    "global quiz_quit\n",
    "quiz_quit=False\n",
    "global prediction_probability_status\n",
    "prediction_probability_status=False\n",
    "\n",
    "\n",
    "width, height = 800, 600\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "video_writer = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "global video_file_name\n",
    "video_file_name=\"\"\n",
    "global audio_file_name\n",
    "audio_file_name=\"\"\n",
    "global split_flag\n",
    "split_flag=False\n",
    "is_on=True\n",
    "recording_is_on=True\n",
    "global show_text\n",
    "show_text=[0]\n",
    "global emotion_flag \n",
    "emotion_flag = False\n",
    "global digit_flag\n",
    "digit_flag = False\n",
    "global alphabet_flag \n",
    "alphabet_flag = False\n",
    "global try_again_quiz\n",
    "try_again_quiz=False\n",
    "global stop_recording\n",
    "stop_recording=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create tkinter root\n",
    "root_instance = Tk()\n",
    "root_instance.geometry(\"{0}x{1}\".format(root_instance.winfo_screenwidth(), root_instance.winfo_screenheight()))\n",
    "# binding escape key on keybord with function that handles session details database saving\n",
    "root_instance.bind('<Escape>', lambda e: closing_fnt()) \n",
    "# Create canvas\n",
    "canvas= Canvas(root_instance, width= 1200, height=200)\n",
    "canvas.pack(fill= BOTH, expand= True)\n",
    "global check_box_variable\n",
    "check_box_variable =IntVar()\n",
    "\n",
    "# images\n",
    "background_img = PhotoImage(file=\"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\backgd.png\")\n",
    "on_image = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\on.png\")\n",
    "off_image = PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\images\\\\off.png\")\n",
    "screen_capture_image =PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\icons\\\\capture_icon.png\")\n",
    "quize_image =PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\icons\\\\quiz.png\")\n",
    "quick_quiz_image =PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\icons\\\\quick_quiz.png\")\n",
    "quit_image =PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\icons\\\\quit.png\")\n",
    "try_image =PhotoImage(file = \"C:\\\\Users\\\\Tessy Benson\\\\Gesturemodel\\\\Consolidate\\\\icons\\\\try.png\")\n",
    "\n",
    "# To show background image\n",
    "canvas.create_image(0,0,image=background_img,anchor='nw') \n",
    "\n",
    "label1 = Label(canvas)\n",
    "label2 = Label(canvas,bd=10,text=\"\")\n",
    "label1.pack(side=LEFT)\n",
    "label1.place(x=300,y=250)\n",
    "label2.pack(side=RIGHT)\n",
    "label2.place(x=1200,y=250)\n",
    "f = Frame(canvas)\n",
    "\n",
    "#defing frame to show the info message at the botton left corner of the interface\n",
    "status_frame = Frame(canvas)\n",
    "global status_variable\n",
    "status_variable=StringVar()        \n",
    "status_label=Label(status_frame,bd=1,fg=\"red\",bg=\"black\",\n",
    "                  textvariable=status_variable, relief=SUNKEN, anchor=\"w\",font=('arial',16,'normal'))\n",
    "status_label.pack(side=BOTTOM, fill=BOTH, expand=1)\n",
    "status_frame.grid(row=2, column=0)\n",
    "status_frame.place(y=965)\n",
    "\n",
    "#label to show the counter time\n",
    "counter_label = Label(canvas,text='00:00:00', font=('Arial', 15),bg='#000', fg='red')\n",
    "counter_label.grid(row=0,column=2,pady=(10,1))\n",
    "counter_label.place(x=1800,y=10)\n",
    "\n",
    "# search frame to show the calender and button\n",
    "search_frame = Frame(canvas)\n",
    "l1=Label(search_frame,text='Search by date')\n",
    "l1.pack(side=LEFT)\n",
    "global date_entry\n",
    "date_entry = DateEntry(search_frame,selectmode='day',maxdate=date.today(),date_pattern = 'dd/mm/yyyy')\n",
    "date_entry.pack(side=LEFT, fill=BOTH, expand=1)\n",
    "btn = Button(search_frame, text='Search',command=lambda : search_functionality(date_entry.get_date()))\n",
    "btn.pack(side=RIGHT)\n",
    "search_frame.grid(row=0,column=3)\n",
    "search_frame.place(x=1450,y=10)\n",
    "\n",
    "#detection button\n",
    "\n",
    "emotion_button=Button(canvas,text='Emotion Detection',state=ACTIVE,font= ('Helvetica 12'),image=on_image, compound= RIGHT,\n",
    "                     command=partial(Detection, 'Emotion Detection'), width=260, height=40)\n",
    "emotion_button.grid(row=1,column=1,padx=(300,5),pady=(100,1))\n",
    "\n",
    "\n",
    "digit_button=Button(canvas,text='Digit Detection',state=ACTIVE,font= ('Helvetica 12'),image=on_image, compound= RIGHT,\n",
    "                     command=partial(Detection, 'Digit Detection'))\n",
    "digit_button.grid(row=1,column=2,padx=(10,5),pady=(100,1))\n",
    "\n",
    "\n",
    "alphabet_button=Button(canvas,text='Alphabet Detection',state=ACTIVE,font= ('Helvetica 12'),image=on_image, compound= RIGHT,\n",
    "                     command=partial(Detection, 'Alphabet Detection'),width=260, height=40)\n",
    "alphabet_button.grid(row=1,column=3,padx=(10,5),pady=(100,1))\n",
    "\n",
    "# screen capture button\n",
    "screenshot_button=Button(canvas,text='Screen Capture',state=ACTIVE,font= ('Helvetica 12'),image=screen_capture_image, compound= RIGHT,\n",
    "                     command=screen_capture)\n",
    "screenshot_button.grid(row=1,column=4,padx=(10,5),pady=(100,1))\n",
    "\n",
    "#quizbutton\n",
    "quiz_button=Button(canvas,state=ACTIVE,font= ('Helvetica 12'),image=quize_image,text='Quiz',compound= RIGHT,\n",
    "                     command=open_quiz_window)\n",
    "quiz_button.grid(row=1,column=5,padx=(10,5),pady=(100,1))\n",
    "\n",
    "#quick quiz button\n",
    "\n",
    "quick_quiz_button=Button(canvas,state=ACTIVE,font= ('Helvetica 12'),image=quick_quiz_image,text='Quick_Quiz',compound= RIGHT,\n",
    "                     command=quick_quiz)\n",
    "quick_quiz_button.grid(row=1,column=6,padx=(10,5),pady=(100,1))\n",
    "quiz_frame = Frame(canvas)\n",
    "\n",
    "# recording button\n",
    "recording_button=Button(canvas,text='Recording',state=ACTIVE,font= ('Helvetica 12'),image=on_image, compound= RIGHT,\n",
    "                     command=Recording)\n",
    "recording_button.grid(row=1,column=7,padx=(10,5),pady=(100,1))\n",
    "\n",
    "\n",
    "counter_start()\n",
    "show_webcam_only()\n",
    "#binding events of  main interface\n",
    "canvas.bind(\"<Configure>\", background_image_resize)\n",
    "root_instance.protocol(\"WM_DELETE_WINDOW\", closing_fnt)\n",
    "root_instance.mainloop()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999852b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b92d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
